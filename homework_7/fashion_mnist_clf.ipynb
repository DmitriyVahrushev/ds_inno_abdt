{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from future.utils import iteritems\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal as mvn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    def fit(self, X, Y, smoothing=1e-2):\n",
    "        self.gaussians = dict()\n",
    "        self.priors = dict()\n",
    "        N, D = X.shape\n",
    "        labels = set(Y)\n",
    "        for c in labels:\n",
    "            current_x = X[Y == c]\n",
    "            self.gaussians[c] = {\n",
    "                'mean': current_x.mean(axis=0),\n",
    "                'var': np.cov(current_x.T) + np.eye(D)*smoothing,\n",
    "            }\n",
    "            self.priors[c] = float(len(Y[Y == c])) / len(Y)\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        P = self.predict(X)\n",
    "        return np.mean(P == Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        N, D = X.shape\n",
    "        K = len(self.gaussians)\n",
    "        P = np.zeros((N, K))\n",
    "        for c, g in iteritems(self.gaussians):\n",
    "            mean, cov = g['mean'], g['var']\n",
    "            P[:,c] = mvn.logpdf(X, mean=mean, cov=cov) + np.log(self.priors[c])\n",
    "        return np.argmax(P, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path = 'data/fashion-mnist_train.csv', limit=None):\n",
    "    print(\"Reading in and transforming data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    data = df.values\n",
    "    np.random.shuffle(data)\n",
    "    X = data[:, 1:] / 255.0 # data is from 0..255\n",
    "    Y = data[:, 0]\n",
    "    if limit is not None:\n",
    "        X, Y = X[:limit], Y[:limit]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = NaiveBayes()\n",
    "#model = SVC()\n",
    "    #model = KNeighborsClassifier(5)\n",
    "    #model = BaggingClassifier(NaiveBayes(),\n",
    "    #                         max_samples=1.0, max_features=1.0)\n",
    "    \n",
    "    #estimators = [\n",
    "        #('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "     #('svr', LinearSVC(random_state=42)), ('svr2', SVC()), ('knn', KNeighborsClassifier(5)), ('logreg',LogisticRegression()) ]\n",
    "    #model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "    #model = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "    #model = LinearSVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_data()\n",
    "pca = PCA(n_components=300)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 400)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:03:16.798559\n",
      "Test accuracy: 0.8995333333333333\n",
      "Time to compute test accuracy: 0:01:51.725752 Test size: 15000\n"
     ]
    }
   ],
   "source": [
    "model = best_svm\n",
    "\n",
    "t0 = datetime.now()\n",
    "best_logreg = model.fit(Xtrain, Ytrain)\n",
    "print(\"Training time:\", (datetime.now() - t0))\n",
    "\n",
    "#t0 = datetime.now()\n",
    "#print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "#print(\"Time to compute train accuracy:\", (datetime.now() - t0), \"Train size:\", len(Ytrain))\n",
    "\n",
    "t0 = datetime.now()\n",
    "print(\"Test accuracy:\", model.score(Xtest, Ytest))\n",
    "print(\"Time to compute test accuracy:\", (datetime.now() - t0), \"Test size:\", len(Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/new_test.csv')\n",
    "data = df.values\n",
    "real_testX = data / 255.0 # data is from 0..255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_testX = pca.fit_transform(real_testX)\n",
    "real_testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 63 candidates, totalling 189 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 189 out of 189 | elapsed: 13.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:13:49.239417\n",
      "Test accuracy: 0.8716\n",
      "Time to compute test accuracy: 0:00:04.609141 Test size: 2500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Xtrain = preprocessing.scale(Xtrain)\n",
    "#Xtest = preprocessing.scale(Xtest)\n",
    "\n",
    "svm_clf = SVC(random_state=42)\n",
    "\n",
    "# Create regularization penalty space\n",
    "degree = [3, 5,6]\n",
    "\n",
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "C = [0.1,0.5,1,2,3,10, 100]\n",
    "kernel  = ['rbf','poly', 'linear']\n",
    "hyperparameters = [dict(C=C, degree=degree, kernel = kernel)] \n",
    "\n",
    "tuned_svm = GridSearchCV(svm_clf, hyperparameters, cv=3, verbose=1, n_jobs=-1)\n",
    "#tuned_svm = svm_clf\n",
    "    \n",
    "t0 = datetime.now()\n",
    "tuned_svm.fit(Xtrain, Ytrain)\n",
    "best_logreg = tuned_svm\n",
    "\n",
    "print(\"Training time:\", (datetime.now() - t0))\n",
    "\n",
    "#t0 = datetime.now()\n",
    "#print(\"Train accuracy:\", best_logreg.score(Xtrain, Ytrain))\n",
    "#print(\"Time to compute train accuracy:\", (datetime.now() - t0), \"Train size:\", len(Ytrain))\n",
    "\n",
    "t0 = datetime.now()\n",
    "print(\"Test accuracy:\", best_logreg.score(Xtest, Ytest))\n",
    "print(\"Time to compute test accuracy:\", (datetime.now() - t0), \"Test size:\", len(Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=3, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm = best_logreg.best_estimator_\n",
    "best_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_data(10000)\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y)  \n",
    "#Xtrain = preprocessing.scale(Xtrain)\n",
    "#Xtest = preprocessing.scale(Xtest)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "C = [0.1,0.5,1,2,3]\n",
    "iterations  = [100,200, 50, 150]\n",
    "hyperparameters = [dict(C=C, penalty=penalty, max_iter = iterations)] \n",
    "\n",
    "tuned_logreg = GridSearchCV(logreg, hyperparameters, cv=3, verbose=1, n_jobs=-1)\n",
    "#tuned_logreg = LogisticRegression()\n",
    "    \n",
    "t0 = datetime.now()\n",
    "best_logreg = tuned_logreg.fit(Xtrain, Ytrain)\n",
    "print(\"Training time:\", (datetime.now() - t0))\n",
    "\n",
    "t0 = datetime.now()\n",
    "print(\"Train accuracy:\", best_logreg.score(Xtrain, Ytrain))\n",
    "print(\"Time to compute train accuracy:\", (datetime.now() - t0), \"Train size:\", len(Ytrain))\n",
    "\n",
    "t0 = datetime.now()\n",
    "print(\"Test accuracy:\", best_logreg.score(Xtest, Ytest))\n",
    "print(\"Time to compute test accuracy:\", (datetime.now() - t0), \"Test size:\", len(Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitriy/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:02:37.569246\n",
      "Train accuracy: 0.8844\n",
      "Time to compute train accuracy: 0:01:25.679305 Train size: 7500\n",
      "Test accuracy: 0.818\n",
      "Time to compute test accuracy: 0:00:28.331947 Test size: 2500\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "neighbors = [1,2,3,4,5,7]\n",
    "hyperparameters = [{'n_neighbors': neighbors}]\n",
    "tuned_knn = RandomizedSearchCV(knn, hyperparameters, random_state=1, n_iter=10, cv=4, verbose=1, n_jobs=-1)\n",
    "\n",
    "    \n",
    "t0 = datetime.now()\n",
    "best_knn = tuned_knn.fit(Xtrain, Ytrain)\n",
    "print(\"Training time:\", (datetime.now() - t0))\n",
    "\n",
    "t0 = datetime.now()\n",
    "print(\"Train accuracy:\", best_knn.score(Xtrain, Ytrain))\n",
    "print(\"Time to compute train accuracy:\", (datetime.now() - t0), \"Train size:\", len(Ytrain))\n",
    "\n",
    "t0 = datetime.now()\n",
    "print(\"Test accuracy:\", best_knn.score(Xtest, Ytest))\n",
    "print(\"Time to compute test accuracy:\", (datetime.now() - t0), \"Test size:\", len(Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'max_iter': 100, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logreg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitriy/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/dmitriy/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/dmitriy/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/dmitriy/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/dmitriy/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/dmitriy/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:02:03.493982\n"
     ]
    }
   ],
   "source": [
    "estimators = [('svr2', best_svm), ('logreg',LogisticRegression(C = 0.1, max_iter=100, penalty = 'l2')) ]\n",
    "stacking = StackingClassifier(estimators=estimators, final_estimator=SVC())\n",
    "\n",
    "t0 = datetime.now()\n",
    "#stacking.fit(Xtrain, Ytrain)\n",
    "stacking.fit(X, Y)\n",
    "print(\"Training time:\", (datetime.now() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackingdatetime.now()\n",
    "print(\"Train accuracy:\", stacking.score(Xtrain, Ytrain))\n",
    "print(\"Time to compute train accuracy:\", (datetime.now() - t0), \"Train size:\", len(Ytrain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9468\n",
      "Time to compute test accuracy: 0:00:06.833413 Test size: 2500\n"
     ]
    }
   ],
   "source": [
    "t0 = datetime.now()\n",
    "print(\"Test accuracy:\", stacking.score(Xtest, Ytest))\n",
    "print(\"Time to compute test accuracy:\", (datetime.now() - t0), \"Test size:\", len(Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = stacking.predict(real_testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 3, ..., 0, 7, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(zip(range(1,len(preds)+1), preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1      3\n",
       "1   2      6\n",
       "2   3      3\n",
       "3   4      6\n",
       "4   5      1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(k, columns = [\"id\", \"label\"])\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"submits/subm_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           1\n",
       "1           2\n",
       "2           3\n",
       "3           4\n",
       "4           5\n",
       "5           6\n",
       "6           7\n",
       "7           8\n",
       "8           9\n",
       "9          10\n",
       "10         11\n",
       "11         12\n",
       "12         13\n",
       "13         14\n",
       "14         15\n",
       "15         16\n",
       "16         17\n",
       "17         18\n",
       "18         19\n",
       "19         20\n",
       "20         21\n",
       "21         22\n",
       "22         23\n",
       "23         24\n",
       "24         25\n",
       "25         26\n",
       "26         27\n",
       "27         28\n",
       "28         29\n",
       "29         30\n",
       "        ...  \n",
       "9970     9971\n",
       "9971     9972\n",
       "9972     9973\n",
       "9973     9974\n",
       "9974     9975\n",
       "9975     9976\n",
       "9976     9977\n",
       "9977     9978\n",
       "9978     9979\n",
       "9979     9980\n",
       "9980     9981\n",
       "9981     9982\n",
       "9982     9983\n",
       "9983     9984\n",
       "9984     9985\n",
       "9985     9986\n",
       "9986     9987\n",
       "9987     9988\n",
       "9988     9989\n",
       "9989     9990\n",
       "9990     9991\n",
       "9991     9992\n",
       "9992     9993\n",
       "9993     9994\n",
       "9994     9995\n",
       "9995     9996\n",
       "9996     9997\n",
       "9997     9998\n",
       "9998     9999\n",
       "9999    10000\n",
       "Name: id, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'models/model_88acc_stacking_svc_linearsvc_logreg.sav'\n",
    "pickle.dump(stacking, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=4)),\n",
       "                               ('logreg', LogisticRegression(C=0.1))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'gaussians'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-20960d9970e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussians\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussians\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'var'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'gaussians'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "label = 9\n",
    "D = len(model.gaussians[label]['mean'])\n",
    "var = np.zeros((D, D))\n",
    "var += np.eye(D) * model.gaussians[label]['var']\n",
    "\n",
    "sample = 255*np.random.multivariate_normal(model.gaussians[label]['mean'], var)\n",
    "\n",
    "pixels = sample.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
